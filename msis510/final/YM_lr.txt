> heart.df <- read.csv("heart.csv", stringsAsFactors = TRUE)> > View(heart.df)> str(heart.df)'data.frame':	303 obs. of  14 variables: $ age     : int  63 37 41 56 57 57 56 44 52 57 ... $ sex     : int  1 1 0 1 0 1 0 1 1 1 ... $ cp      : int  3 2 1 1 0 0 1 1 2 2 ... $ trestbps: int  145 130 130 120 120 140 140 120 172 150 ... $ chol    : int  233 250 204 236 354 192 294 263 199 168 ... $ fbs     : int  1 0 0 0 0 0 0 0 1 0 ... $ restecg : int  0 1 0 1 1 1 0 1 1 1 ... $ thalach : int  150 187 172 178 163 148 153 173 162 174 ... $ exang   : int  0 0 0 0 1 0 0 0 0 0 ... $ oldpeak : num  2.3 3.5 1.4 0.8 0.6 0.4 1.3 0 0.5 1.6 ... $ slope   : int  0 0 2 2 2 1 1 2 2 2 ... $ ca      : int  0 0 0 0 0 0 0 0 0 0 ... $ thal    : int  1 2 2 2 2 1 2 3 3 2 ... $ target  : int  1 1 1 1 1 1 1 1 1 1 ...> > # transform to a factor> heart.df$sex <- factor(heart.df$sex)> heart.df$sex <- relevel(heart.df$sex, ref = "0")> > heart.df$cp <- factor(heart.df$cp)> heart.df$cp <- relevel(heart.df$cp, ref = "0")> > heart.df$fbs <- factor(heart.df$fbs)> heart.df$fbs <- relevel(heart.df$fbs, ref = "0")> > heart.df$restecg <- factor(heart.df$restecg)> heart.df$restecg <- relevel(heart.df$restecg, ref = "0")> > heart.df$exang <- factor(heart.df$exang)> heart.df$exang <- relevel(heart.df$exang, ref = "0")> > heart.df$slope <- factor(heart.df$slope)> heart.df$slope <- relevel(heart.df$slope, ref = "0")> > heart.df$ca <- factor(heart.df$ca)> heart.df$ca <- relevel(heart.df$ca, ref = "0")> > heart.df$thal <- factor(heart.df$thal)> heart.df$thal <- relevel(heart.df$thal, ref = "0")> > #levels(heart.df$thal)> > > heart.df$target <- as.numeric(heart.df$target == "1")> > > # create training and validation sets> set.seed(5)> > # partition the data> train.index <- sample(1:nrow(heart.df), nrow(heart.df)*0.6)  > train.df <- heart.df[train.index, ]> valid.df <- heart.df[-train.index, ]> > # run logistic model, and show coefficients > logit.reg <- glm(target ~ ., data = heart.df, family = "binomial")> summary(logit.reg)Call:glm(formula = target ~ ., family = "binomial", data = heart.df)Deviance Residuals:     Min       1Q   Median       3Q      Max  -2.9459  -0.2738   0.1012   0.4515   3.1248  Coefficients:             Estimate Std. Error z value Pr(>|z|)    (Intercept)  0.179045   3.705420   0.048 0.961461    age          0.027819   0.025428   1.094 0.273938    sex1        -1.862297   0.570844  -3.262 0.001105 ** cp1          0.864708   0.578000   1.496 0.134645    cp2          2.003186   0.529356   3.784 0.000154 ***cp3          2.417107   0.719242   3.361 0.000778 ***trestbps    -0.026162   0.011943  -2.191 0.028481 *  chol        -0.004291   0.004245  -1.011 0.312053    fbs1         0.445666   0.587977   0.758 0.448472    restecg1     0.460582   0.399615   1.153 0.249089    restecg2    -0.714204   2.768873  -0.258 0.796453    thalach      0.020055   0.011859   1.691 0.090820 .  exang1      -0.779111   0.451839  -1.724 0.084652 .  oldpeak     -0.397174   0.242346  -1.639 0.101239    slope1      -0.775084   0.880495  -0.880 0.378707    slope2       0.689965   0.947657   0.728 0.466568    ca1         -2.342301   0.527416  -4.441 8.95e-06 ***ca2         -3.483178   0.811640  -4.292 1.77e-05 ***ca3         -2.247144   0.937629  -2.397 0.016547 *  ca4          1.267961   1.720014   0.737 0.461013    thal1        2.637558   2.684285   0.983 0.325808    thal2        2.367747   2.596159   0.912 0.361759    thal3        0.915115   2.600380   0.352 0.724901    ---Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1(Dispersion parameter for binomial family taken to be 1)    Null deviance: 417.64  on 302  degrees of freedomResidual deviance: 179.63  on 280  degrees of freedomAIC: 225.63Number of Fisher Scoring iterations: 6> > > # use predict() with type = "response" to compute predicted probabilities> # if type not specified, log-odds will be returned> logit.reg.pred <- predict(logit.reg, valid.df,  type = "response")> > > # Choose cutoff value and evaluate classification performance> pred <- ifelse(logit.reg.pred > 0.5, 1, 0)> > ## generate the confusion matrix based on the prediction> library(caret)> confusionMatrix(factor(pred), factor(valid.df$target), positive = "1")Confusion Matrix and Statistics          ReferencePrediction  0  1         0 50  3         1 10 59                                                        Accuracy : 0.8934                          95% CI : (0.8247, 0.942)    No Information Rate : 0.5082             P-Value [Acc > NIR] : < 2e-16                                                                   Kappa : 0.7864                                                   Mcnemar's Test P-Value : 0.09609                                                             Sensitivity : 0.9516                     Specificity : 0.8333                  Pos Pred Value : 0.8551                  Neg Pred Value : 0.9434                      Prevalence : 0.5082                  Detection Rate : 0.4836            Detection Prevalence : 0.5656               Balanced Accuracy : 0.8925                                                         'Positive' Class : 1                                                       > > > > library(pROC)> > r <- roc(valid.df$target, logit.reg.pred)Setting levels: control = 0, case = 1Setting direction: controls < cases> plot.roc(r)> > # find the best threshold> coords(r, x = "best", transpose = FALSE)  threshold specificity sensitivity1 0.5940905   0.8833333   0.9354839> > #coords(r, x = c(0.1, 0.2, 0.5),  transpose = FALSE)> heart.df <- read.csv("heart.csv", stringsAsFactors = TRUE)> > View(heart.df)> str(heart.df)'data.frame':	303 obs. of  14 variables: $ age     : int  63 37 41 56 57 57 56 44 52 57 ... $ sex     : int  1 1 0 1 0 1 0 1 1 1 ... $ cp      : int  3 2 1 1 0 0 1 1 2 2 ... $ trestbps: int  145 130 130 120 120 140 140 120 172 150 ... $ chol    : int  233 250 204 236 354 192 294 263 199 168 ... $ fbs     : int  1 0 0 0 0 0 0 0 1 0 ... $ restecg : int  0 1 0 1 1 1 0 1 1 1 ... $ thalach : int  150 187 172 178 163 148 153 173 162 174 ... $ exang   : int  0 0 0 0 1 0 0 0 0 0 ... $ oldpeak : num  2.3 3.5 1.4 0.8 0.6 0.4 1.3 0 0.5 1.6 ... $ slope   : int  0 0 2 2 2 1 1 2 2 2 ... $ ca      : int  0 0 0 0 0 0 0 0 0 0 ... $ thal    : int  1 2 2 2 2 1 2 3 3 2 ... $ target  : int  1 1 1 1 1 1 1 1 1 1 ...> > # transform to a factor> heart.df$sex <- factor(heart.df$sex)> heart.df$sex <- relevel(heart.df$sex, ref = "0")> > heart.df$cp <- factor(heart.df$cp)> heart.df$cp <- relevel(heart.df$cp, ref = "0")> > heart.df$fbs <- factor(heart.df$fbs)> heart.df$fbs <- relevel(heart.df$fbs, ref = "0")> > heart.df$restecg <- factor(heart.df$restecg)> heart.df$restecg <- relevel(heart.df$restecg, ref = "0")> > heart.df$exang <- factor(heart.df$exang)> heart.df$exang <- relevel(heart.df$exang, ref = "0")> > heart.df$slope <- factor(heart.df$slope)> heart.df$slope <- relevel(heart.df$slope, ref = "0")> > heart.df$ca <- factor(heart.df$ca)> heart.df$ca <- relevel(heart.df$ca, ref = "0")> > heart.df$thal <- factor(heart.df$thal)> heart.df$thal <- relevel(heart.df$thal, ref = "0")> > #levels(heart.df$thal)> > > heart.df$target <- as.numeric(heart.df$target == "1")> > > # create training and validation sets> set.seed(5)> > # partition the data> train.index <- sample(1:nrow(heart.df), nrow(heart.df)*0.6)  > train.df <- heart.df[train.index, ]> valid.df <- heart.df[-train.index, ]> > # run logistic model, and show coefficients > logit.reg <- glm(target ~ ., data = heart.df, family = "binomial")> summary(logit.reg)Call:glm(formula = target ~ ., family = "binomial", data = heart.df)Deviance Residuals:     Min       1Q   Median       3Q      Max  -2.9459  -0.2738   0.1012   0.4515   3.1248  Coefficients:             Estimate Std. Error z value Pr(>|z|)    (Intercept)  0.179045   3.705420   0.048 0.961461    age          0.027819   0.025428   1.094 0.273938    sex1        -1.862297   0.570844  -3.262 0.001105 ** cp1          0.864708   0.578000   1.496 0.134645    cp2          2.003186   0.529356   3.784 0.000154 ***cp3          2.417107   0.719242   3.361 0.000778 ***trestbps    -0.026162   0.011943  -2.191 0.028481 *  chol        -0.004291   0.004245  -1.011 0.312053    fbs1         0.445666   0.587977   0.758 0.448472    restecg1     0.460582   0.399615   1.153 0.249089    restecg2    -0.714204   2.768873  -0.258 0.796453    thalach      0.020055   0.011859   1.691 0.090820 .  exang1      -0.779111   0.451839  -1.724 0.084652 .  oldpeak     -0.397174   0.242346  -1.639 0.101239    slope1      -0.775084   0.880495  -0.880 0.378707    slope2       0.689965   0.947657   0.728 0.466568    ca1         -2.342301   0.527416  -4.441 8.95e-06 ***ca2         -3.483178   0.811640  -4.292 1.77e-05 ***ca3         -2.247144   0.937629  -2.397 0.016547 *  ca4          1.267961   1.720014   0.737 0.461013    thal1        2.637558   2.684285   0.983 0.325808    thal2        2.367747   2.596159   0.912 0.361759    thal3        0.915115   2.600380   0.352 0.724901    ---Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1(Dispersion parameter for binomial family taken to be 1)    Null deviance: 417.64  on 302  degrees of freedomResidual deviance: 179.63  on 280  degrees of freedomAIC: 225.63Number of Fisher Scoring iterations: 6> > > # use predict() with type = "response" to compute predicted probabilities> # if type not specified, log-odds will be returned> logit.reg.pred <- predict(logit.reg, valid.df,  type = "response")> > > # Choose cutoff value and evaluate classification performance> pred <- ifelse(logit.reg.pred > 0.59, 1, 0)> > ## generate the confusion matrix based on the prediction> library(caret)> confusionMatrix(factor(pred), factor(valid.df$target), positive = "1")Confusion Matrix and Statistics          ReferencePrediction  0  1         0 53  4         1  7 58                                                         Accuracy : 0.9098                           95% CI : (0.8444, 0.9541)    No Information Rate : 0.5082              P-Value [Acc > NIR] : <2e-16                                                                      Kappa : 0.8195                                                     Mcnemar's Test P-Value : 0.5465                                                                Sensitivity : 0.9355                      Specificity : 0.8833                   Pos Pred Value : 0.8923                   Neg Pred Value : 0.9298                       Prevalence : 0.5082                   Detection Rate : 0.4754             Detection Prevalence : 0.5328                Balanced Accuracy : 0.9094                                                           'Positive' Class : 1                                                         > > > > library(pROC)> > r <- roc(valid.df$target, logit.reg.pred)Setting levels: control = 0, case = 1Setting direction: controls < cases> plot.roc(r)> > # find the best threshold> coords(r, x = "best", transpose = FALSE)  threshold specificity sensitivity1 0.5940905   0.8833333   0.9354839> 